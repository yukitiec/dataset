{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## single frame analysis: whether there are large spatta?\n",
    "import cv2\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "from numpy import dtype,uint8\n",
    "import scipy.ndimage as ndimage\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Check number of images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#20220401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,1):: 540\n",
      "(1,2):: 537\n",
      "(2,1):: 1080\n",
      "(2,2):: 1079\n",
      "(3,1):: 2162\n",
      "(3,2):: 2162\n",
      "(4,1):: 540\n",
      "(4,2):: 540\n",
      "(5,1):: 1080\n",
      "(5,2):: 1081\n",
      "(6,1):: 2163\n",
      "(6,2):: 2162\n",
      "(7,1):: 540\n",
      "(7,2):: 540\n",
      "(8,1):: 1082\n",
      "(8,2):: 1079\n",
      "(9,1):: 2161\n",
      "(9,2):: 2162\n",
      "(10,1):: 540\n",
      "(10,2):: 540\n",
      "(11,1):: 1080\n",
      "(11,2):: 1080\n",
      "(12,1):: 2161\n",
      "(12,2):: 2092\n"
     ]
    }
   ],
   "source": [
    "dir = r'C:\\Users\\Furukawa\\Documents\\TechAssistant\\dataset\\imgs\\20220401'\n",
    "def checkNum(dir=dir,date_20221020=False):\n",
    "    for i in range(1,13):\n",
    "        for j in range(1,3):\n",
    "            if date_20221020 :\n",
    "                src_img_dir = os.path.join(dir,\"{}\\crop\".format((i-1)*2+j+20))\n",
    "            else:\n",
    "                #get num of file in a directory\n",
    "                src_img_dir = os.path.join(dir,\"{}_{}\\crop\".format(i,j))\n",
    "\n",
    "            num_photo = sum(os.path.isfile(os.path.join(src_img_dir,name)) for name in os.listdir(src_img_dir))\n",
    "\n",
    "            print(f\"({i},{j})::\",num_photo)\n",
    "\n",
    "checkNum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#20220603"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,1):: 540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,2):: 533\n",
      "(2,1):: 1079\n",
      "(2,2):: 1080\n",
      "(3,1):: 2162\n",
      "(3,2):: 2163\n",
      "(4,1):: 457\n",
      "(4,2):: 540\n",
      "(5,1):: 1079\n",
      "(5,2):: 1080\n",
      "(6,1):: 2162\n",
      "(6,2):: 2162\n",
      "(7,1):: 541\n",
      "(7,2):: 540\n",
      "(8,1):: 1080\n",
      "(8,2):: 1080\n",
      "(9,1):: 2162\n",
      "(9,2):: 2163\n",
      "(10,1):: 539\n",
      "(10,2):: 539\n",
      "(11,1):: 1080\n",
      "(11,2):: 1079\n",
      "(12,1):: 2162\n",
      "(12,2):: 2162\n"
     ]
    }
   ],
   "source": [
    "DIR_20220603 = r'C:\\Users\\Furukawa\\Documents\\TechAssistant\\dataset\\imgs\\20220603'\n",
    "checkNum(dir = DIR_20220603)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#20221020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,1):: 244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,2):: 448\n",
      "(2,1):: 895\n",
      "(2,2):: 245\n",
      "(3,1):: 448\n",
      "(3,2):: 863\n",
      "(4,1):: 235\n",
      "(4,2):: 430\n",
      "(5,1):: 857\n",
      "(5,2):: 233\n",
      "(6,1):: 312\n",
      "(6,2):: 880\n",
      "(7,1):: 236\n",
      "(7,2):: 434\n",
      "(8,1):: 866\n",
      "(8,2):: 240\n",
      "(9,1):: 440\n",
      "(9,2):: 883\n",
      "(10,1):: 240\n",
      "(10,2):: 442\n",
      "(11,1):: 889\n",
      "(11,2):: 242\n",
      "(12,1):: 447\n",
      "(12,2):: 892\n"
     ]
    }
   ],
   "source": [
    "DIR_20221020 = r'C:\\Users\\Furukawa\\Documents\\TechAssistant\\dataset\\imgs\\20221020'\n",
    "checkNum(dir = DIR_20221020,date_20221020=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#concatenate imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatImg(x_patch = 3, y_patch = 3,INVERSE = True):\n",
    "    h,w,c = 80,80,1\n",
    "    H = h*3\n",
    "    W = w*3\n",
    "    concat = np.zeros((H,W,c))\n",
    "    folder_path = r'C:\\Users\\Furukawa\\Documents\\TechAssistant\\dataset\\imgs\\20220401\\1_1\\crop'\n",
    "    for i in range(9):\n",
    "        file = \"{:04d}.jpg\".format(i+10)\n",
    "        path = os.path.join(folder_path,file)\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        img = np.expand_dims(np.array(img).astype(\"int32\"),2)\n",
    "        #new to old\n",
    "        if INVERSE:\n",
    "            row =  (x_patch-1) - i//3\n",
    "            column = (y_patch-1) - i%3\n",
    "            concat[h*row:h*(row+1),w*column:w*(column+1),:] = img\n",
    "        #old to new\n",
    "        else:\n",
    "            row = i//3\n",
    "            column = i%3\n",
    "            concat[h*row:h*(row+1),w*column:w*(column+1),:] = img\n",
    "    cv2.imwrite(r'C:\\Users\\Furukawa\\Documents\\TechAssistant\\dataset\\imgs\\20220401\\concat_inverse.jpg',concat)\n",
    "\n",
    "concatImg(INVERSE=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "\n",
    "class Dataset():\n",
    "  def __init__(self,x_patch = 3, y_patch = 3, height = 80,width = 80,\n",
    "                date = \"20220401\",\n",
    "                src_dir = r'C:\\Users\\Furukawa\\Documents\\TechAssistant\\dataset\\imgs\\20220401'\n",
    "              ):\n",
    "    #num of patches\n",
    "    self.x_patch = x_patch\n",
    "    self.y_patch = y_patch  \n",
    "    #size for 1 patch\n",
    "    self.height = height\n",
    "    self.width = width\n",
    "    #size for concatenated img\n",
    "    self.H = x_patch*height\n",
    "    self.W = y_patch*width\n",
    "    #date of dataset\n",
    "    self.date = date\n",
    "    #img src directory\n",
    "    self.src_dir = src_dir\n",
    "    #load spatter labels from .txt file\n",
    "    if date == \"20220401\":\n",
    "        dir=r'C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20220401\\video'\n",
    "        self.spatter_data_1_1 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(1,1)), dtype='int').tolist() #in coping with text file which divide data with space, remove delimiter params. \n",
    "        self.spatter_data_1_2 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(1,2)), dtype='int').tolist()\n",
    "        self.spatter_data_2_1 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(2,1)), dtype='int').tolist()\n",
    "        self.spatter_data_2_2 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(2,2)), dtype='int').tolist()\n",
    "        self.spatter_data_3_1 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(3,1)), dtype='int').tolist()\n",
    "        self.spatter_data_3_2 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(3,2)), dtype='int').tolist()\n",
    "        self.spatter_data_4_1 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(4,1)), dtype='int').tolist()\n",
    "        self.spatter_data_4_2 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(4,2)), dtype='int').tolist()\n",
    "        self.spatter_data_5_1 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(5,1)), dtype='int').tolist()\n",
    "        self.spatter_data_5_2 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(5,2)), dtype='int').tolist()\n",
    "        self.spatter_data_6_1 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(6,1)), dtype='int').tolist()\n",
    "        self.spatter_data_6_2 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(6,2)), dtype='int').tolist()\n",
    "        self.spatter_data_7_1 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(7,1)), dtype='int').tolist()\n",
    "        self.spatter_data_7_2 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(7,2)), dtype='int').tolist()\n",
    "        self.spatter_data_8_1 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(8,1)), dtype='int').tolist()\n",
    "        self.spatter_data_8_2 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(8,2)), dtype='int').tolist()\n",
    "        self.spatter_data_9_1 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(9,1)), dtype='int').tolist()\n",
    "        self.spatter_data_9_2 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(9,2)), dtype='int').tolist()\n",
    "        self.spatter_data_10_1 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(10,1)), dtype='int').tolist()\n",
    "        self.spatter_data_10_2 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(10,2)), dtype='int').tolist()\n",
    "        self.spatter_data_11_1 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(11,1)),dtype='int').tolist()\n",
    "        self.spatter_data_11_2 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(11,2)), dtype='int').tolist()\n",
    "        self.spatter_data_12_1 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(12,1)), dtype='int').tolist()\n",
    "        self.spatter_data_12_2 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(12,2)), dtype='int').tolist()\n",
    "\n",
    "    if date == \"20220603\":\n",
    "        dir = r'C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20220603\\video'\n",
    "        head  = \"xiQ_20220603\"\n",
    "        self.spatter_data_1_1 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,1,1)), dtype='int').tolist()\n",
    "        self.spatter_data_1_2 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,1,2)), dtype='int').tolist()\n",
    "        self.spatter_data_2_1 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,2,1)), dtype='int').tolist()\n",
    "        self.spatter_data_2_2 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,2,2)), dtype='int').tolist()\n",
    "        self.spatter_data_3_1 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,3,1)), dtype='int').tolist()\n",
    "        self.spatter_data_3_2 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,3,2)), dtype='int').tolist()\n",
    "        self.spatter_data_4_1 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,4,1)), dtype='int').tolist()\n",
    "        self.spatter_data_4_2 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,4,2)), dtype='int').tolist()\n",
    "        self.spatter_data_5_1 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,5,1)), dtype='int').tolist()\n",
    "        self.spatter_data_5_2 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,5,2)), dtype='int').tolist()\n",
    "        self.spatter_data_6_1 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,6,1)), dtype='int').tolist()\n",
    "        self.spatter_data_6_2 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,6,2)), dtype='int').tolist()\n",
    "        self.spatter_data_7_1 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,7,1)), dtype='int').tolist()\n",
    "        self.spatter_data_7_2 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,7,2)), dtype='int').tolist()\n",
    "        self.spatter_data_8_1 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,8,1)), dtype='int').tolist()\n",
    "        self.spatter_data_8_2 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,8,2)), dtype='int').tolist()\n",
    "        self.spatter_data_9_1 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,9,1)), dtype='int').tolist()\n",
    "        self.spatter_data_9_2 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,9,2)), dtype='int').tolist()\n",
    "        self.spatter_data_10_1 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,10,1)), dtype='int').tolist()\n",
    "        self.spatter_data_10_2 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,10,2)), dtype='int').tolist()\n",
    "        self.spatter_data_11_1 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,11,1)), dtype='int').tolist()\n",
    "        self.spatter_data_11_2 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,11,2)), dtype='int').tolist()\n",
    "        self.spatter_data_12_1 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,12,1)), dtype='int').tolist()\n",
    "        self.spatter_data_12_2 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,12,2)), dtype='int').tolist()\n",
    "    \n",
    "    if date == \"20221020\":\n",
    "        dir = r'C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20221020\\video'\n",
    "        head  = \"XIMEA_221020\"\n",
    "        self.spatter_data_1_1 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,21)), dtype='int').tolist()\n",
    "        self.spatter_data_1_2 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,22)), dtype='int').tolist()\n",
    "        self.spatter_data_2_1 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,23)), dtype='int').tolist()\n",
    "        self.spatter_data_2_2 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,24)), dtype='int').tolist()\n",
    "        self.spatter_data_3_1 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,25)), dtype='int').tolist()\n",
    "        self.spatter_data_3_2 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,26)), dtype='int').tolist()\n",
    "        self.spatter_data_4_1 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,27)), dtype='int').tolist()\n",
    "        self.spatter_data_4_2 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,28)), dtype='int').tolist()\n",
    "        self.spatter_data_5_1 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,29)), dtype='int').tolist()\n",
    "        self.spatter_data_5_2 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,30)), dtype='int').tolist()\n",
    "        self.spatter_data_6_1 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,31)), dtype='int').tolist()\n",
    "        self.spatter_data_6_2 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,32)), dtype='int').tolist()\n",
    "        self.spatter_data_7_1 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,33)), dtype='int').tolist()\n",
    "        self.spatter_data_7_2 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,34)), dtype='int').tolist()\n",
    "        self.spatter_data_8_1 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,35)), dtype='int').tolist()\n",
    "        self.spatter_data_8_2 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,36)), dtype='int').tolist()\n",
    "        self.spatter_data_9_1 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,37)), dtype='int').tolist()\n",
    "        self.spatter_data_9_2 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,38)), dtype='int').tolist()\n",
    "        self.spatter_data_10_1 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,39)), dtype='int').tolist()\n",
    "        self.spatter_data_10_2 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,40)), dtype='int').tolist()\n",
    "        self.spatter_data_11_1 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,41)), dtype='int').tolist()\n",
    "        self.spatter_data_11_2 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,42)), dtype='int').tolist()\n",
    "        self.spatter_data_12_1 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,43)), dtype='int').tolist()\n",
    "        self.spatter_data_12_2 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,44)), dtype='int').tolist()\n",
    "\n",
    "  def checkImg(self,file_path):\n",
    "    \"\"\"check whether laser process has started\n",
    "\n",
    "    Args:\n",
    "        file_path (str): img file path\n",
    "    \"\"\"\n",
    "    img = cv2.imread(file_path)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    gray = gray\n",
    "    ret,thresh = cv2.threshold(gray,60,255,cv2.THRESH_BINARY)\n",
    "    #find contours\n",
    "    contours, hierarchy = cv2.findContours(np.array(thresh,dtype=uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    Area = []\n",
    "    #detect laser area\n",
    "    if (bool(contours)==True):\n",
    "      #面積(px*px)\n",
    "      for j in contours:\n",
    "        area = cv2.contourArea(j)\n",
    "        Area.append(area)\n",
    "\n",
    "      if Area:\n",
    "        area_max = np.max(Area)\n",
    "        if area_max > 64:\n",
    "           ret = True\n",
    "           return ret\n",
    "        else:\n",
    "           ret = False\n",
    "           return ret\n",
    "      else:\n",
    "         ret = False\n",
    "         return ret\n",
    "      \n",
    "  # adjust the number of no spatter below 51\n",
    "  def make(self,filename,filename_test,div,sec):\n",
    "    #フォルダに存在するファイルを取得する、0001.jpg~0005.jpg→{}/*.jpg\n",
    "    \n",
    "    #spatter label \n",
    "    if self.date == \"20220401\":\n",
    "      spatter = [[[],[]],\n",
    "                [self.spatter_data_1_1,self.spatter_data_1_2],\n",
    "                [self.spatter_data_2_1,self.spatter_data_2_2],\n",
    "                [self.spatter_data_3_1,self.spatter_data_3_2],\n",
    "                [self.spatter_data_4_1,self.spatter_data_4_2],\n",
    "                [self.spatter_data_5_1,self.spatter_data_5_2],\n",
    "                [self.spatter_data_6_1,self.spatter_data_6_2],\n",
    "                [self.spatter_data_7_1,self.spatter_data_7_2],\n",
    "                [self.spatter_data_8_1,self.spatter_data_8_2],\n",
    "                [self.spatter_data_9_1,self.spatter_data_9_2],\n",
    "                [self.spatter_data_10_1,self.spatter_data_10_2],\n",
    "                [self.spatter_data_11_1,self.spatter_data_11_2],\n",
    "                [self.spatter_data_12_1,self.spatter_data_12_2]]\n",
    "    elif self.date == \"20220603\":\n",
    "       spatter = [[[],[]],\n",
    "                [self.spatter_data_1_1,self.spatter_data_1_2],\n",
    "                [self.spatter_data_2_1,self.spatter_data_2_2],\n",
    "                [self.spatter_data_3_1,self.spatter_data_3_2],\n",
    "                [[self.spatter_data_4_1],self.spatter_data_4_2],\n",
    "                [self.spatter_data_5_1,self.spatter_data_5_2],\n",
    "                [self.spatter_data_6_1,self.spatter_data_6_2],\n",
    "                [[self.spatter_data_7_1],[self.spatter_data_7_2]],\n",
    "                [self.spatter_data_8_1,self.spatter_data_8_2],\n",
    "                [self.spatter_data_9_1,self.spatter_data_9_2],\n",
    "                [self.spatter_data_10_1,self.spatter_data_10_2],\n",
    "                [self.spatter_data_11_1,self.spatter_data_11_2],\n",
    "                [self.spatter_data_12_1,self.spatter_data_12_2]]\n",
    "    elif self.date == \"20221020\":\n",
    "       spatter = [[[],[]],\n",
    "                [self.spatter_data_1_1,self.spatter_data_1_2],\n",
    "                [[self.spatter_data_2_1],self.spatter_data_2_2],\n",
    "                [self.spatter_data_3_1,[self.spatter_data_3_2]],\n",
    "                [[self.spatter_data_4_1],[self.spatter_data_4_2]],\n",
    "                [self.spatter_data_5_1,[self.spatter_data_5_2]],\n",
    "                [self.spatter_data_6_1,self.spatter_data_6_2],\n",
    "                [self.spatter_data_7_1,[self.spatter_data_7_2]],\n",
    "                [[self.spatter_data_8_1],[self.spatter_data_8_2]],\n",
    "                [[self.spatter_data_9_1],self.spatter_data_9_2],\n",
    "                [self.spatter_data_10_1,[self.spatter_data_10_2]],\n",
    "                [self.spatter_data_11_1,[self.spatter_data_11_2]],\n",
    "                [self.spatter_data_12_1,self.spatter_data_12_2]]\n",
    "    \n",
    "    if self.date == \"20220401\"  or self.date == \"20220603\":\n",
    "      #set src img directory\n",
    "      src_img_dir = os.path.join(self.src_dir,\"{}_{}\\crop\".format(div,sec))\n",
    "    elif self.date == \"20221020\":\n",
    "      #set src img directory\n",
    "      src_img_dir = os.path.join(self.src_dir,\"{}\\crop\".format((div-1)*2+sec+20))\n",
    "\n",
    "    #spatter count\n",
    "    count_spatter = 0\n",
    "    count_nonspatter = 0\n",
    "    #get num of file in a directory\n",
    "    num_photo = sum(os.path.isfile(os.path.join(src_img_dir,name)) for name in os.listdir(src_img_dir))\n",
    "    print(\"{}-{} progressing :: {}\".format(div,sec,num_photo))\n",
    "    #make dataset\n",
    "    for i in range(10,num_photo-10):\n",
    "      file_path = os.path.join(src_img_dir,f\"{i:04d}.jpg\")\n",
    "      ret = self.checkImg(file_path=file_path)\n",
    "      #laser welding has started\n",
    "      if ret :\n",
    "        #spater frame\n",
    "        if (((i+10) in spatter[div-1][sec-1]) or ((i+9) in spatter[div-1][sec-1]) or ((i+8) in spatter[div-1][sec-1]) or \n",
    "            ((i+7) in spatter[div-1][sec-1]) or ((i+6) in spatter[div-1][sec-1]) or ((i+5) in spatter[div-1][sec-1]) or \n",
    "            ((i+4) in spatter[div-1][sec-1]) or ((i+3) in spatter[div-1][sec-1]) or ((i+2) in spatter[div-1][sec-1])):  \n",
    "          #whether spatter frame is included in input frame\n",
    "          if ((i not in spatter[div-1][sec-1]) and ((i-1) not in spatter[div-1][sec-1]) and ((i-2) not in spatter[div-1][sec-1]) and \n",
    "              ((i-3) not in spatter[div-1][sec-1]) and ((i-4) not in spatter[div-1][sec-1]) and ((i-5) not in spatter[div-1][sec-1]) and \n",
    "            ((i-6) not in spatter[div-1][sec-1]) and ((i-7) not in spatter[div-1][sec-1]) and ((i-8) not in spatter[div-1][sec-1]) and\n",
    "            ((i-9) not in spatter[div-1][sec-1])):\n",
    "            #file path : new to old, file0 ~ file9\n",
    "            file0 = file_path\n",
    "            file1 = os.path.join(src_img_dir,f\"{(i-1):04d}.jpg\")\n",
    "            file2 = os.path.join(src_img_dir,f\"{(i-2):04d}.jpg\")\n",
    "            file3 = os.path.join(src_img_dir,f\"{(i-3):04d}.jpg\")\n",
    "            file4 = os.path.join(src_img_dir,f\"{(i-4):04d}.jpg\")\n",
    "            file5 = os.path.join(src_img_dir,f\"{(i-5):04d}.jpg\")\n",
    "            file6 = os.path.join(src_img_dir,f\"{(i-6):04d}.jpg\")\n",
    "            file7 = os.path.join(src_img_dir,f\"{(i-7):04d}.jpg\")\n",
    "            file8 = os.path.join(src_img_dir,f\"{(i-8):04d}.jpg\")\n",
    "            file9 = os.path.join(src_img_dir,f\"{(i-9):04d}.jpg\")\n",
    "            #write data to csv file\n",
    "            if random.random() >= 0.1: #85% is train data\n",
    "              with open(filename,\"a\",newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([1,file0,file1,file2,file3,file4,file5,file6,file7,file8,file9])\n",
    "            else:\n",
    "              with open(filename_test,\"a\",newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([1,file0,file1,file2,file3,file4,file5,file6,file7,file8,file9])\n",
    "            count_spatter += 1\n",
    "        #non-spatter frame\n",
    "        else:\n",
    "          #whether spatter frame is included in input frame\n",
    "          if ((i not in spatter[div-1][sec-1]) and ((i-1) not in spatter[div-1][sec-1]) and ((i-2) not in spatter[div-1][sec-1]) and \n",
    "              ((i-3) not in spatter[div-1][sec-1]) and ((i-4) not in spatter[div-1][sec-1]) and ((i-5) not in spatter[div-1][sec-1]) and \n",
    "            ((i-6) not in spatter[div-1][sec-1]) and ((i-7) not in spatter[div-1][sec-1]) and ((i-8) not in spatter[div-1][sec-1]) and \n",
    "            ((i-9) not in spatter[div-1][sec-1])) :\n",
    "            #random function for variety of dataset\n",
    "            if random.random() >= 0.9:\n",
    "              #file path : new to old, file0 ~ file9\n",
    "              file0 = file_path\n",
    "              file1 = os.path.join(src_img_dir,f\"{(i-1):04d}.jpg\")\n",
    "              file2 = os.path.join(src_img_dir,f\"{(i-2):04d}.jpg\")\n",
    "              file3 = os.path.join(src_img_dir,f\"{(i-3):04d}.jpg\")\n",
    "              file4 = os.path.join(src_img_dir,f\"{(i-4):04d}.jpg\")\n",
    "              file5 = os.path.join(src_img_dir,f\"{(i-5):04d}.jpg\")\n",
    "              file6 = os.path.join(src_img_dir,f\"{(i-6):04d}.jpg\")\n",
    "              file7 = os.path.join(src_img_dir,f\"{(i-7):04d}.jpg\")\n",
    "              file8 = os.path.join(src_img_dir,f\"{(i-8):04d}.jpg\")\n",
    "              file9 = os.path.join(src_img_dir,f\"{(i-9):04d}.jpg\")\n",
    "              #write data to csv file\n",
    "              if random.random() >= 0.1: #85% is train data\n",
    "                with open(filename,\"a\",newline='') as f:\n",
    "                  writer = csv.writer(f)\n",
    "                  writer.writerow([0,file0,file1,file2,file3,file4,file5,file6,file7,file8,file9])\n",
    "              else:\n",
    "                with open(filename_test,\"a\",newline='') as f:\n",
    "                  writer = csv.writer(f)\n",
    "                  writer.writerow([0,file0,file1,file2,file3,file4,file5,file6,file7,file8,file9])\n",
    "                \n",
    "              count_nonspatter += 1\n",
    "    print(f\"Finished! Spatter :: {count_spatter}, Non-spatter :: {count_nonspatter}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#20220401"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Initialize dataset file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Initialize csv dataset?\n",
    "INITIALIZE = True\n",
    "\n",
    "\n",
    "\n",
    "#prepare csv files\n",
    "file_dir = r'C:\\Users\\Furukawa\\Documents\\TechAssistant\\dataset\\csv\\resNet'\n",
    "filename=os.path.join(file_dir,\"train.csv\")\n",
    "filename_test=os.path.join(file_dir,\"test.csv\")\n",
    "#///////////////////\n",
    "if INITIALIZE:\n",
    "  #make csv file\n",
    "  with open(filename,\"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Spatter\",\"Path(t)\",\"Path(t-1)\",\"Path(t-2)\",\"Path(t-3)\",\"Path(t-4)\",\"Path(t-5)\",\"Path(t-6)\",\"Path(t-7)\",\"Path(t-8)\",\"Path(t-9)\"])\n",
    "\n",
    "  with open(filename_test,\"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Spatter\",\"Path(t)\",\"Path(t-1)\",\"Path(t-2)\",\"Path(t-3)\",\"Path(t-4)\",\"Path(t-5)\",\"Path(t-6)\",\"Path(t-7)\",\"Path(t-8)\",\"Path(t-9)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20220401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-1 progressing :: 540\n",
      "Finished! Spatter :: 0, Non-spatter :: 50\n",
      "1-2 progressing :: 537\n",
      "Finished! Spatter :: 0, Non-spatter :: 70\n",
      "2-1 progressing :: 1080\n",
      "Finished! Spatter :: 35, Non-spatter :: 144\n",
      "2-2 progressing :: 1079\n",
      "Finished! Spatter :: 28, Non-spatter :: 132\n",
      "3-1 progressing :: 2162\n",
      "Finished! Spatter :: 103, Non-spatter :: 208\n",
      "3-2 progressing :: 2162\n",
      "Finished! Spatter :: 123, Non-spatter :: 238\n",
      "4-1 progressing :: 540\n",
      "Finished! Spatter :: 41, Non-spatter :: 49\n",
      "4-2 progressing :: 540\n",
      "Finished! Spatter :: 30, Non-spatter :: 50\n",
      "5-1 progressing :: 1080\n",
      "Finished! Spatter :: 53, Non-spatter :: 115\n",
      "5-2 progressing :: 1081\n",
      "Finished! Spatter :: 30, Non-spatter :: 83\n",
      "6-1 progressing :: 2163\n",
      "Finished! Spatter :: 136, Non-spatter :: 216\n",
      "6-2 progressing :: 2162\n",
      "Finished! Spatter :: 148, Non-spatter :: 181\n",
      "7-1 progressing :: 540\n",
      "Finished! Spatter :: 65, Non-spatter :: 39\n",
      "7-2 progressing :: 540\n",
      "Finished! Spatter :: 64, Non-spatter :: 45\n",
      "8-1 progressing :: 1082\n",
      "Finished! Spatter :: 40, Non-spatter :: 122\n",
      "8-2 progressing :: 1079\n",
      "Finished! Spatter :: 51, Non-spatter :: 100\n",
      "9-1 progressing :: 2161\n",
      "Finished! Spatter :: 161, Non-spatter :: 160\n",
      "9-2 progressing :: 2162\n",
      "Finished! Spatter :: 157, Non-spatter :: 187\n",
      "10-1 progressing :: 540\n",
      "Finished! Spatter :: 49, Non-spatter :: 26\n",
      "10-2 progressing :: 540\n",
      "Finished! Spatter :: 49, Non-spatter :: 43\n",
      "11-1 progressing :: 1080\n",
      "Finished! Spatter :: 40, Non-spatter :: 106\n",
      "11-2 progressing :: 1080\n",
      "Finished! Spatter :: 47, Non-spatter :: 100\n",
      "12-1 progressing :: 2161\n",
      "Finished! Spatter :: 149, Non-spatter :: 156\n",
      "12-2 progressing :: 2092\n",
      "Finished! Spatter :: 158, Non-spatter :: 166\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(x_patch = 3, y_patch = 3, height = 80,width = 80,\n",
    "                date = \"20220401\",\n",
    "                src_dir = r'C:\\Users\\Furukawa\\Documents\\TechAssistant\\dataset\\imgs\\20220401',\n",
    "                )\n",
    "\n",
    "#make dataset one by one\n",
    "for i in range(1,13):\n",
    "  for j in range(1,3):\n",
    "    dataset.make(filename=filename,filename_test=filename_test,div = i,sec = j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#check dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4071, 11)\n",
      "(472, 11)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_train = pd.read_csv(filename)\n",
    "train = file_train.values\n",
    "print(train.shape)\n",
    "file_test = pd.read_csv(filename_test)\n",
    "test = file_test.values\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20220603"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-1 progressing :: 540\n",
      "Finished! Spatter :: 0, Non-spatter :: 74\n",
      "1-2 progressing :: 533\n",
      "Finished! Spatter :: 0, Non-spatter :: 32\n",
      "2-1 progressing :: 1079\n",
      "Finished! Spatter :: 9, Non-spatter :: 123\n",
      "2-2 progressing :: 1080\n",
      "Finished! Spatter :: 0, Non-spatter :: 107\n",
      "3-1 progressing :: 2162\n",
      "Finished! Spatter :: 9, Non-spatter :: 282\n",
      "3-2 progressing :: 2163\n",
      "Finished! Spatter :: 18, Non-spatter :: 244\n",
      "4-1 progressing :: 457\n",
      "Finished! Spatter :: 19, Non-spatter :: 52\n",
      "4-2 progressing :: 540\n",
      "Finished! Spatter :: 18, Non-spatter :: 59\n",
      "5-1 progressing :: 1079\n",
      "Finished! Spatter :: 0, Non-spatter :: 125\n",
      "5-2 progressing :: 1080\n",
      "Finished! Spatter :: 18, Non-spatter :: 124\n",
      "6-1 progressing :: 2162\n",
      "Finished! Spatter :: 18, Non-spatter :: 271\n",
      "6-2 progressing :: 2162\n",
      "Finished! Spatter :: 34, Non-spatter :: 259\n",
      "7-1 progressing :: 541\n",
      "Finished! Spatter :: 20, Non-spatter :: 68\n",
      "7-2 progressing :: 540\n",
      "Finished! Spatter :: 28, Non-spatter :: 48\n",
      "8-1 progressing :: 1080\n",
      "Finished! Spatter :: 0, Non-spatter :: 128\n",
      "8-2 progressing :: 1080\n",
      "Finished! Spatter :: 0, Non-spatter :: 138\n",
      "9-1 progressing :: 2162\n",
      "Finished! Spatter :: 10, Non-spatter :: 260\n",
      "9-2 progressing :: 2163\n",
      "Finished! Spatter :: 39, Non-spatter :: 254\n",
      "10-1 progressing :: 539\n",
      "Finished! Spatter :: 24, Non-spatter :: 49\n",
      "10-2 progressing :: 539\n",
      "Finished! Spatter :: 51, Non-spatter :: 39\n",
      "11-1 progressing :: 1080\n",
      "Finished! Spatter :: 18, Non-spatter :: 117\n",
      "11-2 progressing :: 1079\n",
      "Finished! Spatter :: 9, Non-spatter :: 117\n",
      "12-1 progressing :: 2162\n",
      "Finished! Spatter :: 55, Non-spatter :: 252\n",
      "12-2 progressing :: 2162\n",
      "Finished! Spatter :: 85, Non-spatter :: 240\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(x_patch = 3, y_patch = 3, height = 80,width = 80,\n",
    "                date = \"20220603\",\n",
    "                src_dir = r'C:\\Users\\Furukawa\\Documents\\TechAssistant\\dataset\\imgs\\20220603'\n",
    "                )\n",
    "\n",
    "#make dataset one by one\n",
    "for i in range(1,13):\n",
    "  for j in range(1,3):\n",
    "    dataset.make(filename=filename,filename_test=filename_test,div = i,sec = j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7658, 11)\n",
      "(829, 11)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_train = pd.read_csv(filename)\n",
    "train = file_train.values\n",
    "print(train.shape)\n",
    "file_test = pd.read_csv(filename_test)\n",
    "test = file_test.values\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#20221020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-1 progressing :: 244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Furukawa\\AppData\\Local\\Temp\\ipykernel_34232\\4259939171.py:83: UserWarning: loadtxt: input contained no data: \"C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20221020\\video\\XIMEA_221020_21_trim_spatter.txt\"\n",
      "  self.spatter_data_1_1 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,21)), dtype='int').tolist()\n",
      "C:\\Users\\Furukawa\\AppData\\Local\\Temp\\ipykernel_34232\\4259939171.py:84: UserWarning: loadtxt: input contained no data: \"C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20221020\\video\\XIMEA_221020_22_trim_spatter.txt\"\n",
      "  self.spatter_data_1_2 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,22)), dtype='int').tolist()\n",
      "C:\\Users\\Furukawa\\AppData\\Local\\Temp\\ipykernel_34232\\4259939171.py:86: UserWarning: loadtxt: input contained no data: \"C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20221020\\video\\XIMEA_221020_24_trim_spatter.txt\"\n",
      "  self.spatter_data_2_2 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,24)), dtype='int').tolist()\n",
      "C:\\Users\\Furukawa\\AppData\\Local\\Temp\\ipykernel_34232\\4259939171.py:87: UserWarning: loadtxt: input contained no data: \"C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20221020\\video\\XIMEA_221020_25_trim_spatter.txt\"\n",
      "  self.spatter_data_3_1 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,25)), dtype='int').tolist()\n",
      "C:\\Users\\Furukawa\\AppData\\Local\\Temp\\ipykernel_34232\\4259939171.py:95: UserWarning: loadtxt: input contained no data: \"C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20221020\\video\\XIMEA_221020_33_trim_spatter.txt\"\n",
      "  self.spatter_data_7_1 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,33)), dtype='int').tolist()\n",
      "C:\\Users\\Furukawa\\AppData\\Local\\Temp\\ipykernel_34232\\4259939171.py:101: UserWarning: loadtxt: input contained no data: \"C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20221020\\video\\XIMEA_221020_39_trim_spatter.txt\"\n",
      "  self.spatter_data_10_1 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,39)), dtype='int').tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished! Spatter :: 0, Non-spatter :: 25\n",
      "1-2 progressing :: 448\n",
      "Finished! Spatter :: 0, Non-spatter :: 54\n",
      "2-1 progressing :: 895\n",
      "Finished! Spatter :: 0, Non-spatter :: 105\n",
      "2-2 progressing :: 245\n",
      "Finished! Spatter :: 0, Non-spatter :: 33\n",
      "3-1 progressing :: 448\n",
      "Finished! Spatter :: 0, Non-spatter :: 55\n",
      "3-2 progressing :: 863\n",
      "Finished! Spatter :: 0, Non-spatter :: 94\n",
      "4-1 progressing :: 235\n",
      "Finished! Spatter :: 0, Non-spatter :: 45\n",
      "4-2 progressing :: 430\n",
      "Finished! Spatter :: 8, Non-spatter :: 53\n",
      "5-1 progressing :: 857\n",
      "Finished! Spatter :: 9, Non-spatter :: 118\n",
      "5-2 progressing :: 233\n",
      "Finished! Spatter :: 7, Non-spatter :: 39\n",
      "6-1 progressing :: 312\n",
      "Finished! Spatter :: 0, Non-spatter :: 45\n",
      "6-2 progressing :: 880\n",
      "Finished! Spatter :: 0, Non-spatter :: 116\n",
      "7-1 progressing :: 236\n",
      "Finished! Spatter :: 6, Non-spatter :: 23\n",
      "7-2 progressing :: 434\n",
      "Finished! Spatter :: 18, Non-spatter :: 33\n",
      "8-1 progressing :: 866\n",
      "Finished! Spatter :: 0, Non-spatter :: 77\n",
      "8-2 progressing :: 240\n",
      "Finished! Spatter :: 8, Non-spatter :: 33\n",
      "9-1 progressing :: 440\n",
      "Finished! Spatter :: 9, Non-spatter :: 55\n",
      "9-2 progressing :: 883\n",
      "Finished! Spatter :: 9, Non-spatter :: 93\n",
      "10-1 progressing :: 240\n",
      "Finished! Spatter :: 8, Non-spatter :: 30\n",
      "10-2 progressing :: 442\n",
      "Finished! Spatter :: 18, Non-spatter :: 44\n",
      "11-1 progressing :: 889\n",
      "Finished! Spatter :: 0, Non-spatter :: 92\n",
      "11-2 progressing :: 242\n",
      "Finished! Spatter :: 0, Non-spatter :: 34\n",
      "12-1 progressing :: 447\n",
      "Finished! Spatter :: 62, Non-spatter :: 32\n",
      "12-2 progressing :: 892\n",
      "Finished! Spatter :: 0, Non-spatter :: 119\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(x_patch = 3, y_patch = 3, height = 80,width = 80,\n",
    "                date = \"20221020\",\n",
    "                src_dir = r'C:\\Users\\Furukawa\\Documents\\TechAssistant\\dataset\\imgs\\20221020'\n",
    "                )\n",
    "\n",
    "#make dataset one by one\n",
    "for i in range(1,13):\n",
    "  for j in range(1,3):\n",
    "    dataset.make(filename=filename,filename_test=filename_test,div = i,sec = j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9095, 11)\n",
      "(1001, 11)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_train = pd.read_csv(filename)\n",
    "train = file_train.values\n",
    "print(train.shape)\n",
    "file_test = pd.read_csv(filename_test)\n",
    "test = file_test.values\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#total dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9095, 11)\n",
      "(1001, 11)\n",
      "train data\n",
      "Spatter/toal : 2141/9095\n",
      "test data\n",
      "Spatter/toal : 260/1001\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_train = pd.read_csv(filename)\n",
    "train = file_train.values\n",
    "labels_train = train[:,0]\n",
    "print(train.shape)\n",
    "file_test = pd.read_csv(filename_test)\n",
    "test = file_test.values\n",
    "labels_test = test[:,0]\n",
    "print(test.shape)\n",
    "def count_spatter(labels):\n",
    "    count = 0\n",
    "    for i in range(labels.shape[0]):\n",
    "        if labels[i] == 1:\n",
    "            count += 1\n",
    "    print(f\"Spatter/toal : {count}/{labels.shape[0]}\")\n",
    "\n",
    "print(\"train data\")\n",
    "count_spatter(labels_train)\n",
    "print(\"test data\")\n",
    "count_spatter(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "furukawa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
