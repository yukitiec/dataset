{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## single frame analysis: whether there are large spatta?\n",
    "import cv2\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "from numpy import dtype,uint8\n",
    "import scipy.ndimage as ndimage\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Check number of images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#20220401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,1):: 540\n",
      "(1,2):: 537\n",
      "(2,1):: 1080\n",
      "(2,2):: 1079\n",
      "(3,1):: 2162\n",
      "(3,2):: 2162\n",
      "(4,1):: 540\n",
      "(4,2):: 540\n",
      "(5,1):: 1080\n",
      "(5,2):: 1081\n",
      "(6,1):: 2163\n",
      "(6,2):: 2162\n",
      "(7,1):: 540\n",
      "(7,2):: 540\n",
      "(8,1):: 1082\n",
      "(8,2):: 1079\n",
      "(9,1):: 2161\n",
      "(9,2):: 2162\n",
      "(10,1):: 540\n",
      "(10,2):: 540\n",
      "(11,1):: 1080\n",
      "(11,2):: 1080\n",
      "(12,1):: 2161\n",
      "(12,2):: 2092\n"
     ]
    }
   ],
   "source": [
    "dir = r'C:\\Users\\Furukawa\\Documents\\TechAssistant\\dataset\\imgs\\20220401'\n",
    "def checkNum(dir=dir,date_20221020=False):\n",
    "    for i in range(1,13):\n",
    "        for j in range(1,3):\n",
    "            if date_20221020 :\n",
    "                src_img_dir = os.path.join(dir,\"{}\\crop\".format((i-1)*2+j+20))\n",
    "            else:\n",
    "                #get num of file in a directory\n",
    "                src_img_dir = os.path.join(dir,\"{}_{}\\crop\".format(i,j))\n",
    "\n",
    "            num_photo = sum(os.path.isfile(os.path.join(src_img_dir,name)) for name in os.listdir(src_img_dir))\n",
    "\n",
    "            print(f\"({i},{j})::\",num_photo)\n",
    "\n",
    "checkNum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#20220603"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,1):: 540\n",
      "(1,2):: 533\n",
      "(2,1):: 1079\n",
      "(2,2):: 1080\n",
      "(3,1):: 2162\n",
      "(3,2):: 2163\n",
      "(4,1):: 457\n",
      "(4,2):: 540\n",
      "(5,1):: 1079\n",
      "(5,2):: 1080\n",
      "(6,1):: 2162\n",
      "(6,2):: 2162\n",
      "(7,1):: 541\n",
      "(7,2):: 540\n",
      "(8,1):: 1080\n",
      "(8,2):: 1080\n",
      "(9,1):: 2162\n",
      "(9,2):: 2163\n",
      "(10,1):: 539\n",
      "(10,2):: 539\n",
      "(11,1):: 1080\n",
      "(11,2):: 1079\n",
      "(12,1):: 2162\n",
      "(12,2):: 2162\n"
     ]
    }
   ],
   "source": [
    "DIR_20220603 = r'C:\\Users\\Furukawa\\Documents\\TechAssistant\\dataset\\imgs\\20220603'\n",
    "checkNum(dir = DIR_20220603)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#20221020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,1):: 244\n",
      "(1,2):: 448\n",
      "(2,1):: 895\n",
      "(2,2):: 245\n",
      "(3,1):: 448\n",
      "(3,2):: 863\n",
      "(4,1):: 235\n",
      "(4,2):: 430\n",
      "(5,1):: 857\n",
      "(5,2):: 233\n",
      "(6,1):: 312\n",
      "(6,2):: 880\n",
      "(7,1):: 236\n",
      "(7,2):: 434\n",
      "(8,1):: 866\n",
      "(8,2):: 240\n",
      "(9,1):: 440\n",
      "(9,2):: 883\n",
      "(10,1):: 240\n",
      "(10,2):: 442\n",
      "(11,1):: 889\n",
      "(11,2):: 242\n",
      "(12,1):: 447\n",
      "(12,2):: 892\n"
     ]
    }
   ],
   "source": [
    "DIR_20221020 = r'C:\\Users\\Furukawa\\Documents\\TechAssistant\\dataset\\imgs\\20221020'\n",
    "checkNum(dir = DIR_20221020,date_20221020=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#concatenate imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatImg(x_patch = 3, y_patch = 3,INVERSE = True):\n",
    "    h,w,c = 80,80,1\n",
    "    H = h*3\n",
    "    W = w*3\n",
    "    concat = np.zeros((H,W,c))\n",
    "    folder_path = r'C:\\Users\\Furukawa\\Documents\\TechAssistant\\dataset\\imgs\\20220401\\1_1\\crop'\n",
    "    for i in range(9):\n",
    "        file = \"{:04d}.jpg\".format(i+10)\n",
    "        path = os.path.join(folder_path,file)\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        img = np.expand_dims(np.array(img).astype(\"int32\"),2)\n",
    "        #new to old\n",
    "        if INVERSE:\n",
    "            row =  (x_patch-1) - i//3\n",
    "            column = (y_patch-1) - i%3\n",
    "            concat[h*row:h*(row+1),w*column:w*(column+1),:] = img\n",
    "        #old to new\n",
    "        else:\n",
    "            row = i//3\n",
    "            column = i%3\n",
    "            concat[h*row:h*(row+1),w*column:w*(column+1),:] = img\n",
    "    cv2.imwrite(r'C:\\Users\\Furukawa\\Documents\\TechAssistant\\dataset\\imgs\\20220401\\concat_inverse.jpg',concat)\n",
    "\n",
    "concatImg(INVERSE=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "\n",
    "class Dataset():\n",
    "  def __init__(self,x_patch = 3, y_patch = 3, height = 80,width = 80,\n",
    "                date = \"20220401\",\n",
    "                src_dir = r'C:\\Users\\Furukawa\\Documents\\TechAssistant\\dataset\\imgs\\20220401',\n",
    "                dir_concatImg = \"concat_vit\"\n",
    "              ):\n",
    "    #num of patches\n",
    "    self.x_patch = x_patch\n",
    "    self.y_patch = y_patch  \n",
    "    #size for 1 patch\n",
    "    self.height = height\n",
    "    self.width = width\n",
    "    #size for concatenated img\n",
    "    self.H = x_patch*height\n",
    "    self.W = y_patch*width\n",
    "    #date of dataset\n",
    "    self.date = date\n",
    "    #img src directory\n",
    "    self.src_dir = src_dir\n",
    "    #directory for concat img\n",
    "    self.dir_concatImg = dir_concatImg\n",
    "    #load spatter labels from .txt file\n",
    "    if date == \"20220401\":\n",
    "        dir=r'C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20220401\\video'\n",
    "        self.spatter_data_1_1 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(1,1)), dtype='int').tolist() #in coping with text file which divide data with space, remove delimiter params. \n",
    "        self.spatter_data_1_2 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(1,2)), dtype='int').tolist()\n",
    "        self.spatter_data_2_1 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(2,1)), dtype='int').tolist()\n",
    "        self.spatter_data_2_2 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(2,2)), dtype='int').tolist()\n",
    "        self.spatter_data_3_1 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(3,1)), dtype='int').tolist()\n",
    "        self.spatter_data_3_2 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(3,2)), dtype='int').tolist()\n",
    "        self.spatter_data_4_1 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(4,1)), dtype='int').tolist()\n",
    "        self.spatter_data_4_2 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(4,2)), dtype='int').tolist()\n",
    "        self.spatter_data_5_1 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(5,1)), dtype='int').tolist()\n",
    "        self.spatter_data_5_2 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(5,2)), dtype='int').tolist()\n",
    "        self.spatter_data_6_1 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(6,1)), dtype='int').tolist()\n",
    "        self.spatter_data_6_2 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(6,2)), dtype='int').tolist()\n",
    "        self.spatter_data_7_1 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(7,1)), dtype='int').tolist()\n",
    "        self.spatter_data_7_2 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(7,2)), dtype='int').tolist()\n",
    "        self.spatter_data_8_1 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(8,1)), dtype='int').tolist()\n",
    "        self.spatter_data_8_2 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(8,2)), dtype='int').tolist()\n",
    "        self.spatter_data_9_1 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(9,1)), dtype='int').tolist()\n",
    "        self.spatter_data_9_2 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(9,2)), dtype='int').tolist()\n",
    "        self.spatter_data_10_1 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(10,1)), dtype='int').tolist()\n",
    "        self.spatter_data_10_2 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(10,2)), dtype='int').tolist()\n",
    "        self.spatter_data_11_1 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(11,1)),dtype='int').tolist()\n",
    "        self.spatter_data_11_2 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(11,2)), dtype='int').tolist()\n",
    "        self.spatter_data_12_1 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(12,1)), dtype='int').tolist()\n",
    "        self.spatter_data_12_2 = np.loadtxt(os.path.join(dir,'220401_xiQ_{}-{}_spatter.txt'.format(12,2)), dtype='int').tolist()\n",
    "\n",
    "    if date == \"20220603\":\n",
    "        dir = r'C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20220603\\video'\n",
    "        head  = \"xiQ_20220603\"\n",
    "        self.spatter_data_1_1 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,1,1)), dtype='int').tolist()\n",
    "        self.spatter_data_1_2 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,1,2)), dtype='int').tolist()\n",
    "        self.spatter_data_2_1 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,2,1)), dtype='int').tolist()\n",
    "        self.spatter_data_2_2 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,2,2)), dtype='int').tolist()\n",
    "        self.spatter_data_3_1 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,3,1)), dtype='int').tolist()\n",
    "        self.spatter_data_3_2 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,3,2)), dtype='int').tolist()\n",
    "        self.spatter_data_4_1 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,4,1)), dtype='int').tolist()\n",
    "        self.spatter_data_4_2 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,4,2)), dtype='int').tolist()\n",
    "        self.spatter_data_5_1 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,5,1)), dtype='int').tolist()\n",
    "        self.spatter_data_5_2 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,5,2)), dtype='int').tolist()\n",
    "        self.spatter_data_6_1 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,6,1)), dtype='int').tolist()\n",
    "        self.spatter_data_6_2 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,6,2)), dtype='int').tolist()\n",
    "        self.spatter_data_7_1 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,7,1)), dtype='int').tolist()\n",
    "        self.spatter_data_7_2 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,7,2)), dtype='int').tolist()\n",
    "        self.spatter_data_8_1 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,8,1)), dtype='int').tolist()\n",
    "        self.spatter_data_8_2 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,8,2)), dtype='int').tolist()\n",
    "        self.spatter_data_9_1 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,9,1)), dtype='int').tolist()\n",
    "        self.spatter_data_9_2 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,9,2)), dtype='int').tolist()\n",
    "        self.spatter_data_10_1 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,10,1)), dtype='int').tolist()\n",
    "        self.spatter_data_10_2 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,10,2)), dtype='int').tolist()\n",
    "        self.spatter_data_11_1 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,11,1)), dtype='int').tolist()\n",
    "        self.spatter_data_11_2 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,11,2)), dtype='int').tolist()\n",
    "        self.spatter_data_12_1 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,12,1)), dtype='int').tolist()\n",
    "        self.spatter_data_12_2 = np.loadtxt(os.path.join(dir,'{}_{}-{}_spatter.txt'.format(head,12,2)), dtype='int').tolist()\n",
    "    \n",
    "    if date == \"20221020\":\n",
    "        dir = r'C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20221020\\video'\n",
    "        head  = \"XIMEA_221020\"\n",
    "        self.spatter_data_1_1 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,21)), dtype='int').tolist()\n",
    "        self.spatter_data_1_2 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,22)), dtype='int').tolist()\n",
    "        self.spatter_data_2_1 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,23)), dtype='int').tolist()\n",
    "        self.spatter_data_2_2 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,24)), dtype='int').tolist()\n",
    "        self.spatter_data_3_1 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,25)), dtype='int').tolist()\n",
    "        self.spatter_data_3_2 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,26)), dtype='int').tolist()\n",
    "        self.spatter_data_4_1 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,27)), dtype='int').tolist()\n",
    "        self.spatter_data_4_2 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,28)), dtype='int').tolist()\n",
    "        self.spatter_data_5_1 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,29)), dtype='int').tolist()\n",
    "        self.spatter_data_5_2 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,30)), dtype='int').tolist()\n",
    "        self.spatter_data_6_1 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,31)), dtype='int').tolist()\n",
    "        self.spatter_data_6_2 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,32)), dtype='int').tolist()\n",
    "        self.spatter_data_7_1 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,33)), dtype='int').tolist()\n",
    "        self.spatter_data_7_2 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,34)), dtype='int').tolist()\n",
    "        self.spatter_data_8_1 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,35)), dtype='int').tolist()\n",
    "        self.spatter_data_8_2 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,36)), dtype='int').tolist()\n",
    "        self.spatter_data_9_1 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,37)), dtype='int').tolist()\n",
    "        self.spatter_data_9_2 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,38)), dtype='int').tolist()\n",
    "        self.spatter_data_10_1 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,39)), dtype='int').tolist()\n",
    "        self.spatter_data_10_2 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,40)), dtype='int').tolist()\n",
    "        self.spatter_data_11_1 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,41)), dtype='int').tolist()\n",
    "        self.spatter_data_11_2 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,42)), dtype='int').tolist()\n",
    "        self.spatter_data_12_1 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,43)), dtype='int').tolist()\n",
    "        self.spatter_data_12_2 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,44)), dtype='int').tolist()\n",
    "\n",
    "  def concatImg(self,index,src_img_dir,save_dir,INVERSE = False):\n",
    "      \"\"\"concatenate images\n",
    "      Args:\n",
    "        index: index for spatter frame, so index is the latest index in 9 frames, ie. index, index-1,index-2,..., index-8\n",
    "        src_img_dir : source directory of cropped imgs\n",
    "        save_dir : save dir for concatenate images\n",
    "        x_patch, y_patch : number of patches in x and y axis\n",
    "        INVERSE : patch order. If INVERSE is True, new to old is applied\n",
    "      Return:\n",
    "        file_path : path for concat img\n",
    "        write concatenated images into designated directory\n",
    "      \"\"\"\n",
    "      concat = np.zeros((self.H,self.W,1))\n",
    "      for i in range(9):\n",
    "          file = \"{:04d}.jpg\".format(index-i) #from new to old\n",
    "          path = os.path.join(src_img_dir,file)\n",
    "          img = cv2.imread(path)\n",
    "          img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) #gray scale\n",
    "          img = np.expand_dims(np.array(img).astype(\"int32\"),2) #add color channel : (height,width,1)\n",
    "          #new to old\n",
    "          if INVERSE:\n",
    "              row = i//3\n",
    "              column = i%3\n",
    "              concat[self.height*row:self.height*(row+1),self.width*column:self.width*(column+1),:] = img\n",
    "          #old to new\n",
    "          else:\n",
    "              row =  (self.x_patch-1) - i//3\n",
    "              column = (self.y_patch-1) - i%3\n",
    "              concat[self.height*row:self.height*(row+1),self.width*column:self.width*(column+1),:] = img\n",
    "      file_path = os.path.join(save_dir,f\"{index:04d}.jpg\")\n",
    "      cv2.imwrite(file_path,concat)\n",
    "      return file_path\n",
    "\n",
    "  def checkImg(self,file_path):\n",
    "    \"\"\"check whether laser process has started\n",
    "\n",
    "    Args:\n",
    "        file_path (str): img file path\n",
    "    \"\"\"\n",
    "    img = cv2.imread(file_path)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    gray = gray\n",
    "    ret,thresh = cv2.threshold(gray,60,255,cv2.THRESH_BINARY)\n",
    "    #find contours\n",
    "    contours, hierarchy = cv2.findContours(np.array(thresh,dtype=uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    Area = []\n",
    "    #detect laser area\n",
    "    if (bool(contours)==True):\n",
    "      #面積(px*px)\n",
    "      for j in contours:\n",
    "        area = cv2.contourArea(j)\n",
    "        Area.append(area)\n",
    "\n",
    "      if Area:\n",
    "        area_max = np.max(Area)\n",
    "        if area_max > 64:\n",
    "           ret = True\n",
    "           return ret\n",
    "        else:\n",
    "           ret = False\n",
    "           return ret\n",
    "      else:\n",
    "         ret = False\n",
    "         return ret\n",
    "      \n",
    "  # adjust the number of no spatter below 51\n",
    "  def make(self,filename,filename_test,div,sec):\n",
    "    #フォルダに存在するファイルを取得する、0001.jpg~0005.jpg→{}/*.jpg\n",
    "    \n",
    "    #spatter label \n",
    "    if self.date == \"20220401\":\n",
    "      spatter = [[[],[]],\n",
    "                [self.spatter_data_1_1,self.spatter_data_1_2],\n",
    "                [self.spatter_data_2_1,self.spatter_data_2_2],\n",
    "                [self.spatter_data_3_1,self.spatter_data_3_2],\n",
    "                [self.spatter_data_4_1,self.spatter_data_4_2],\n",
    "                [self.spatter_data_5_1,self.spatter_data_5_2],\n",
    "                [self.spatter_data_6_1,self.spatter_data_6_2],\n",
    "                [self.spatter_data_7_1,self.spatter_data_7_2],\n",
    "                [self.spatter_data_8_1,self.spatter_data_8_2],\n",
    "                [self.spatter_data_9_1,self.spatter_data_9_2],\n",
    "                [self.spatter_data_10_1,self.spatter_data_10_2],\n",
    "                [self.spatter_data_11_1,self.spatter_data_11_2],\n",
    "                [self.spatter_data_12_1,self.spatter_data_12_2]]\n",
    "    elif self.date == \"20220603\":\n",
    "       spatter = [[[],[]],\n",
    "                [self.spatter_data_1_1,self.spatter_data_1_2],\n",
    "                [self.spatter_data_2_1,self.spatter_data_2_2],\n",
    "                [self.spatter_data_3_1,self.spatter_data_3_2],\n",
    "                [[self.spatter_data_4_1],self.spatter_data_4_2],\n",
    "                [self.spatter_data_5_1,self.spatter_data_5_2],\n",
    "                [self.spatter_data_6_1,self.spatter_data_6_2],\n",
    "                [[self.spatter_data_7_1],[self.spatter_data_7_2]],\n",
    "                [self.spatter_data_8_1,self.spatter_data_8_2],\n",
    "                [self.spatter_data_9_1,self.spatter_data_9_2],\n",
    "                [self.spatter_data_10_1,self.spatter_data_10_2],\n",
    "                [self.spatter_data_11_1,self.spatter_data_11_2],\n",
    "                [self.spatter_data_12_1,self.spatter_data_12_2]]\n",
    "    elif self.date == \"20221020\":\n",
    "       spatter = [[[],[]],\n",
    "                [self.spatter_data_1_1,self.spatter_data_1_2],\n",
    "                [[self.spatter_data_2_1],self.spatter_data_2_2],\n",
    "                [self.spatter_data_3_1,[self.spatter_data_3_2]],\n",
    "                [[self.spatter_data_4_1],[self.spatter_data_4_2]],\n",
    "                [self.spatter_data_5_1,[self.spatter_data_5_2]],\n",
    "                [self.spatter_data_6_1,self.spatter_data_6_2],\n",
    "                [self.spatter_data_7_1,[self.spatter_data_7_2]],\n",
    "                [[self.spatter_data_8_1],[self.spatter_data_8_2]],\n",
    "                [[self.spatter_data_9_1],self.spatter_data_9_2],\n",
    "                [self.spatter_data_10_1,[self.spatter_data_10_2]],\n",
    "                [self.spatter_data_11_1,[self.spatter_data_11_2]],\n",
    "                [self.spatter_data_12_1,self.spatter_data_12_2]]\n",
    "    \n",
    "    if self.date == \"20220401\"  or self.date == \"20220603\":\n",
    "      #set src img directory\n",
    "      src_img_dir = os.path.join(self.src_dir,\"{}_{}\\crop\".format(div,sec))\n",
    "      #make save directory\n",
    "      save_dir= os.path.join(self.src_dir,\"{}_{}\\{}\".format(div,sec,self.dir_concatImg))\n",
    "      if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    elif self.date == \"20221020\":\n",
    "      #set src img directory\n",
    "      src_img_dir = os.path.join(self.src_dir,\"{}\\crop\".format((div-1)*2+sec+20))\n",
    "      #make save directory\n",
    "      save_dir= os.path.join(self.src_dir,\"{}\\{}\".format(((div-1)*2+sec+20),self.dir_concatImg))\n",
    "      if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "\n",
    "    #spatter count\n",
    "    count_spatter = 0\n",
    "    count_nonspatter = 0\n",
    "    #get num of file in a directory\n",
    "    num_photo = sum(os.path.isfile(os.path.join(src_img_dir,name)) for name in os.listdir(src_img_dir))\n",
    "    print(\"{}-{} progressing :: {}\".format(div,sec,num_photo))\n",
    "    #make dataset\n",
    "    for i in range(10,num_photo-10):\n",
    "      file_path = os.path.join(src_img_dir,f\"{i:04d}.jpg\")\n",
    "      ret = self.checkImg(file_path=file_path)\n",
    "      #laser welding has started\n",
    "      if ret :\n",
    "        #spater frame\n",
    "        if (((i+10) in spatter[div-1][sec-1]) or ((i+9) in spatter[div-1][sec-1]) or ((i+8) in spatter[div-1][sec-1]) or \n",
    "            ((i+7) in spatter[div-1][sec-1]) or ((i+6) in spatter[div-1][sec-1]) or ((i+5) in spatter[div-1][sec-1]) or \n",
    "            ((i+4) in spatter[div-1][sec-1]) or ((i+3) in spatter[div-1][sec-1]) or ((i+2) in spatter[div-1][sec-1])):  \n",
    "          #whether spatter frame is included in input frame\n",
    "          if ((i not in spatter[div-1][sec-1]) and ((i-1) not in spatter[div-1][sec-1]) and ((i-2) not in spatter[div-1][sec-1]) and \n",
    "              ((i-3) not in spatter[div-1][sec-1]) and ((i-4) not in spatter[div-1][sec-1]) and ((i-5) not in spatter[div-1][sec-1]) and \n",
    "            ((i-6) not in spatter[div-1][sec-1]) and ((i-7) not in spatter[div-1][sec-1]) and ((i-8) not in spatter[div-1][sec-1])) :\n",
    "            #concatenate images\n",
    "            file_path = self.concatImg(index=i,src_img_dir=src_img_dir,save_dir=save_dir,INVERSE = False)\n",
    "            if random.random() >= 0.1: #85% is train data\n",
    "              with open(filename,\"a\",newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([1,file_path])\n",
    "            else:\n",
    "              with open(filename_test,\"a\",newline='') as f:\n",
    "                  writer = csv.writer(f)\n",
    "                  writer.writerow([1,file_path])\n",
    "            count_spatter += 1\n",
    "        #non-spatter frame\n",
    "        else:\n",
    "          #whether spatter frame is included in input frame\n",
    "          if ((i not in spatter[div-1][sec-1]) and ((i-1) not in spatter[div-1][sec-1]) and ((i-2) not in spatter[div-1][sec-1]) and \n",
    "              ((i-3) not in spatter[div-1][sec-1]) and ((i-4) not in spatter[div-1][sec-1]) and ((i-5) not in spatter[div-1][sec-1]) and \n",
    "            ((i-6) not in spatter[div-1][sec-1]) and ((i-7) not in spatter[div-1][sec-1]) and ((i-8) not in spatter[div-1][sec-1])) :\n",
    "            #random function for variety of dataset\n",
    "            if random.random() >= 0.85:\n",
    "              #concatenate images\n",
    "              file_path = self.concatImg(index=i,src_img_dir=src_img_dir,save_dir=save_dir,INVERSE = False)\n",
    "              if random.random() >= 0.1: #85% is train data\n",
    "                with open(filename,\"a\",newline='') as f:\n",
    "                  writer = csv.writer(f)\n",
    "                  writer.writerow([0,file_path])\n",
    "              else:\n",
    "                with open(filename_test,\"a\",newline='') as f:\n",
    "                  writer = csv.writer(f)\n",
    "                  writer.writerow([0,file_path])\n",
    "              count_nonspatter += 1\n",
    "    print(f\"Finished! Spatter :: {count_spatter}, Non-spatter :: {count_nonspatter}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#20220401"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Initialize dataset file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Initialize csv dataset?\n",
    "INITIALIZE = True\n",
    "\n",
    "\n",
    "\n",
    "#prepare csv files\n",
    "file_dir = r'C:\\Users\\Furukawa\\Documents\\TechAssistant\\dataset\\csv\\ViT'\n",
    "filename=os.path.join(file_dir,\"train_vit.csv\")\n",
    "filename_test=os.path.join(file_dir,\"test_vit.csv\")\n",
    "#///////////////////\n",
    "if INITIALIZE:\n",
    "  #make csv file\n",
    "  with open(filename,\"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Spatter\",\"Path\"])\n",
    "\n",
    "  with open(filename_test,\"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Spatter\",\"Path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-1 progressing :: 540\n",
      "Finished! Spatter :: 0, Non-spatter :: 55\n",
      "1-2 progressing :: 537\n",
      "Finished! Spatter :: 0, Non-spatter :: 68\n",
      "2-1 progressing :: 1080\n",
      "Finished! Spatter :: 36, Non-spatter :: 134\n",
      "2-2 progressing :: 1079\n",
      "Finished! Spatter :: 28, Non-spatter :: 110\n",
      "3-1 progressing :: 2162\n",
      "Finished! Spatter :: 105, Non-spatter :: 243\n",
      "3-2 progressing :: 2162\n",
      "Finished! Spatter :: 125, Non-spatter :: 225\n",
      "4-1 progressing :: 540\n",
      "Finished! Spatter :: 43, Non-spatter :: 37\n",
      "4-2 progressing :: 540\n",
      "Finished! Spatter :: 31, Non-spatter :: 56\n",
      "5-1 progressing :: 1080\n",
      "Finished! Spatter :: 54, Non-spatter :: 130\n",
      "5-2 progressing :: 1081\n",
      "Finished! Spatter :: 31, Non-spatter :: 108\n",
      "6-1 progressing :: 2163\n",
      "Finished! Spatter :: 147, Non-spatter :: 227\n",
      "6-2 progressing :: 2162\n",
      "Finished! Spatter :: 157, Non-spatter :: 195\n",
      "7-1 progressing :: 540\n",
      "Finished! Spatter :: 71, Non-spatter :: 38\n",
      "7-2 progressing :: 540\n",
      "Finished! Spatter :: 65, Non-spatter :: 41\n",
      "8-1 progressing :: 1082\n",
      "Finished! Spatter :: 42, Non-spatter :: 101\n",
      "8-2 progressing :: 1079\n",
      "Finished! Spatter :: 54, Non-spatter :: 106\n",
      "9-1 progressing :: 2161\n",
      "Finished! Spatter :: 169, Non-spatter :: 182\n",
      "9-2 progressing :: 2162\n",
      "Finished! Spatter :: 164, Non-spatter :: 188\n",
      "10-1 progressing :: 540\n",
      "Finished! Spatter :: 56, Non-spatter :: 30\n",
      "10-2 progressing :: 540\n",
      "Finished! Spatter :: 53, Non-spatter :: 48\n",
      "11-1 progressing :: 1080\n",
      "Finished! Spatter :: 41, Non-spatter :: 111\n",
      "11-2 progressing :: 1080\n",
      "Finished! Spatter :: 50, Non-spatter :: 112\n",
      "12-1 progressing :: 2161\n",
      "Finished! Spatter :: 160, Non-spatter :: 169\n",
      "12-2 progressing :: 2092\n",
      "Finished! Spatter :: 169, Non-spatter :: 184\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(x_patch = 3, y_patch = 3, height = 80,width = 80,\n",
    "                date = \"20220401\",\n",
    "                src_dir = r'C:\\Users\\Furukawa\\Documents\\TechAssistant\\dataset\\imgs\\20220401',\n",
    "                dir_concatImg = \"concat_vit\"\n",
    "                )\n",
    "\n",
    "#make dataset one by one\n",
    "for i in range(1,13):\n",
    "  for j in range(1,3):\n",
    "    dataset.make(filename=filename,filename_test=filename_test,div = i,sec = j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#check dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3952, 2)\n",
      "(710, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_train = pd.read_csv(filename)\n",
    "train = file_train.values\n",
    "print(train.shape)\n",
    "file_test = pd.read_csv(filename_test)\n",
    "test = file_test.values\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#20220603"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-1 progressing :: 540\n",
      "Finished! Spatter :: 0, Non-spatter :: 67\n",
      "1-2 progressing :: 533\n",
      "Finished! Spatter :: 0, Non-spatter :: 32\n",
      "2-1 progressing :: 1079\n",
      "Finished! Spatter :: 9, Non-spatter :: 123\n",
      "2-2 progressing :: 1080\n",
      "Finished! Spatter :: 0, Non-spatter :: 109\n",
      "3-1 progressing :: 2162\n",
      "Finished! Spatter :: 9, Non-spatter :: 233\n",
      "3-2 progressing :: 2163\n",
      "Finished! Spatter :: 18, Non-spatter :: 249\n",
      "4-1 progressing :: 457\n",
      "Finished! Spatter :: 19, Non-spatter :: 46\n",
      "4-2 progressing :: 540\n",
      "Finished! Spatter :: 18, Non-spatter :: 60\n",
      "5-1 progressing :: 1079\n",
      "Finished! Spatter :: 0, Non-spatter :: 133\n",
      "5-2 progressing :: 1080\n",
      "Finished! Spatter :: 18, Non-spatter :: 126\n",
      "6-1 progressing :: 2162\n",
      "Finished! Spatter :: 18, Non-spatter :: 274\n",
      "6-2 progressing :: 2162\n",
      "Finished! Spatter :: 35, Non-spatter :: 253\n",
      "7-1 progressing :: 541\n",
      "Finished! Spatter :: 21, Non-spatter :: 61\n",
      "7-2 progressing :: 540\n",
      "Finished! Spatter :: 28, Non-spatter :: 70\n",
      "8-1 progressing :: 1080\n",
      "Finished! Spatter :: 0, Non-spatter :: 125\n",
      "8-2 progressing :: 1080\n",
      "Finished! Spatter :: 0, Non-spatter :: 125\n",
      "9-1 progressing :: 2162\n",
      "Finished! Spatter :: 10, Non-spatter :: 268\n",
      "9-2 progressing :: 2163\n",
      "Finished! Spatter :: 40, Non-spatter :: 241\n",
      "10-1 progressing :: 539\n",
      "Finished! Spatter :: 25, Non-spatter :: 53\n",
      "10-2 progressing :: 539\n",
      "Finished! Spatter :: 54, Non-spatter :: 51\n",
      "11-1 progressing :: 1080\n",
      "Finished! Spatter :: 19, Non-spatter :: 136\n",
      "11-2 progressing :: 1079\n",
      "Finished! Spatter :: 9, Non-spatter :: 140\n",
      "12-1 progressing :: 2162\n",
      "Finished! Spatter :: 55, Non-spatter :: 236\n",
      "12-2 progressing :: 2162\n",
      "Finished! Spatter :: 85, Non-spatter :: 253\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(x_patch = 3, y_patch = 3, height = 80,width = 80,\n",
    "                date = \"20220603\",\n",
    "                src_dir = r'C:\\Users\\Furukawa\\Documents\\TechAssistant\\dataset\\imgs\\20220603',\n",
    "                dir_concatImg = \"concat_vit\"\n",
    "                )\n",
    "\n",
    "#make dataset one by one\n",
    "for i in range(1,13):\n",
    "  for j in range(1,3):\n",
    "    dataset.make(filename=filename,filename_test=filename_test,div = i,sec = j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8085, 2)\n",
      "(858, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_train = pd.read_csv(filename)\n",
    "train = file_train.values\n",
    "print(train.shape)\n",
    "file_test = pd.read_csv(filename_test)\n",
    "test = file_test.values\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#20221020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-1 progressing :: 244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Furukawa\\AppData\\Local\\Temp\\ipykernel_63684\\4225067730.py:86: UserWarning: loadtxt: input contained no data: \"C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20221020\\video\\XIMEA_221020_21_trim_spatter.txt\"\n",
      "  self.spatter_data_1_1 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,21)), dtype='int').tolist()\n",
      "C:\\Users\\Furukawa\\AppData\\Local\\Temp\\ipykernel_63684\\4225067730.py:87: UserWarning: loadtxt: input contained no data: \"C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20221020\\video\\XIMEA_221020_22_trim_spatter.txt\"\n",
      "  self.spatter_data_1_2 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,22)), dtype='int').tolist()\n",
      "C:\\Users\\Furukawa\\AppData\\Local\\Temp\\ipykernel_63684\\4225067730.py:89: UserWarning: loadtxt: input contained no data: \"C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20221020\\video\\XIMEA_221020_24_trim_spatter.txt\"\n",
      "  self.spatter_data_2_2 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,24)), dtype='int').tolist()\n",
      "C:\\Users\\Furukawa\\AppData\\Local\\Temp\\ipykernel_63684\\4225067730.py:90: UserWarning: loadtxt: input contained no data: \"C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20221020\\video\\XIMEA_221020_25_trim_spatter.txt\"\n",
      "  self.spatter_data_3_1 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,25)), dtype='int').tolist()\n",
      "C:\\Users\\Furukawa\\AppData\\Local\\Temp\\ipykernel_63684\\4225067730.py:98: UserWarning: loadtxt: input contained no data: \"C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20221020\\video\\XIMEA_221020_33_trim_spatter.txt\"\n",
      "  self.spatter_data_7_1 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,33)), dtype='int').tolist()\n",
      "C:\\Users\\Furukawa\\AppData\\Local\\Temp\\ipykernel_63684\\4225067730.py:104: UserWarning: loadtxt: input contained no data: \"C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20221020\\video\\XIMEA_221020_39_trim_spatter.txt\"\n",
      "  self.spatter_data_10_1 = np.loadtxt(os.path.join(dir,'{}_{}_trim_spatter.txt'.format(head,39)), dtype='int').tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished! Spatter :: 0, Non-spatter :: 26\n",
      "1-2 progressing :: 448\n",
      "Finished! Spatter :: 0, Non-spatter :: 58\n",
      "2-1 progressing :: 895\n",
      "Finished! Spatter :: 0, Non-spatter :: 101\n",
      "2-2 progressing :: 245\n",
      "Finished! Spatter :: 0, Non-spatter :: 34\n",
      "3-1 progressing :: 448\n",
      "Finished! Spatter :: 0, Non-spatter :: 54\n",
      "3-2 progressing :: 863\n",
      "Finished! Spatter :: 0, Non-spatter :: 93\n",
      "4-1 progressing :: 235\n",
      "Finished! Spatter :: 0, Non-spatter :: 31\n",
      "4-2 progressing :: 430\n",
      "Finished! Spatter :: 8, Non-spatter :: 46\n",
      "5-1 progressing :: 857\n",
      "Finished! Spatter :: 9, Non-spatter :: 122\n",
      "5-2 progressing :: 233\n",
      "Finished! Spatter :: 7, Non-spatter :: 34\n",
      "6-1 progressing :: 312\n",
      "Finished! Spatter :: 0, Non-spatter :: 46\n",
      "6-2 progressing :: 880\n",
      "Finished! Spatter :: 0, Non-spatter :: 122\n",
      "7-1 progressing :: 236\n",
      "Finished! Spatter :: 6, Non-spatter :: 22\n",
      "7-2 progressing :: 434\n",
      "Finished! Spatter :: 18, Non-spatter :: 34\n",
      "8-1 progressing :: 866\n",
      "Finished! Spatter :: 0, Non-spatter :: 79\n",
      "8-2 progressing :: 240\n",
      "Finished! Spatter :: 8, Non-spatter :: 31\n",
      "9-1 progressing :: 440\n",
      "Finished! Spatter :: 9, Non-spatter :: 53\n",
      "9-2 progressing :: 883\n",
      "Finished! Spatter :: 9, Non-spatter :: 105\n",
      "10-1 progressing :: 240\n",
      "Finished! Spatter :: 8, Non-spatter :: 32\n",
      "10-2 progressing :: 442\n",
      "Finished! Spatter :: 18, Non-spatter :: 51\n",
      "11-1 progressing :: 889\n",
      "Finished! Spatter :: 0, Non-spatter :: 114\n",
      "11-2 progressing :: 242\n",
      "Finished! Spatter :: 0, Non-spatter :: 38\n",
      "12-1 progressing :: 447\n",
      "Finished! Spatter :: 62, Non-spatter :: 37\n",
      "12-2 progressing :: 892\n",
      "Finished! Spatter :: 0, Non-spatter :: 98\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(x_patch = 3, y_patch = 3, height = 80,width = 80,\n",
    "                date = \"20221020\",\n",
    "                src_dir = r'C:\\Users\\Furukawa\\Documents\\TechAssistant\\dataset\\imgs\\20221020',\n",
    "                dir_concatImg = \"concat_vit\"\n",
    "                )\n",
    "\n",
    "#make dataset one by one\n",
    "for i in range(1,13):\n",
    "  for j in range(1,3):\n",
    "    dataset.make(filename=filename,filename_test=filename_test,div = i,sec = j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9563, 2)\n",
      "(1003, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_train = pd.read_csv(filename)\n",
    "train = file_train.values\n",
    "print(train.shape)\n",
    "file_test = pd.read_csv(filename_test)\n",
    "test = file_test.values\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# total dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9563, 2)\n",
      "(1003, 2)\n",
      "train data\n",
      "Spatter/toal : 2298/9563\n",
      "test data\n",
      "Spatter/toal : 241/1003\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_train = pd.read_csv(filename)\n",
    "train = file_train.values\n",
    "labels_train = train[:,0]\n",
    "print(train.shape)\n",
    "file_test = pd.read_csv(filename_test)\n",
    "test = file_test.values\n",
    "labels_test = test[:,0]\n",
    "print(test.shape)\n",
    "def count_spatter(labels):\n",
    "    count = 0\n",
    "    for i in range(labels.shape[0]):\n",
    "        if labels[i] == 1:\n",
    "            count += 1\n",
    "    print(f\"Spatter/toal : {count}/{labels.shape[0]}\")\n",
    "\n",
    "print(\"train data\")\n",
    "count_spatter(labels_train)\n",
    "print(\"test data\")\n",
    "count_spatter(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "furukawa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
